This project automates the monitoring, processing, and analysis of data files generated by wind turbines using Apache Airflow. The goal is to create a system that efficiently detects the presence of new data files, processes the data, and takes actions based on specific conditions, such as sending alerts when the temperature exceeds a certain threshold.

Project Components

File Sensor Task

- Verifies file presence at regular intervals
- Does not monitor the folder indefinitely
- Does not initialize the DAG when the file becomes available
- Does not retain knowledge of previous DAG executions
  
File Sensor Task Parameters

- filepath: Verifies if the file exists before proceeding.
- fs_conn_id: Connects to the file using Airflow's connection feature. Default connection is fs_default.
  
Wind Turbine Simulation

- Generates a JSON file with the following structure
  {
  "idtemp": "1",
  "powerfactor": "0.8837929080361997",
  "hydraulicpressure": "78.86011124702158",
  "temperature": "25.279809506572597",
  "timestamp": "2023-03-19 17:26:55.230351"
}

- Uses a pre-made file for testing
- A Python notebook simulates the file generation


  Scheduling

- Interval: Every 3 minutes ("*/3 * * * *")
- For development purposes: Set to None

  Operators

PythonOperator:
- Reads the JSON file
- Extracts and stores 5 variables in Xcom
- Deletes the file after processing
BranchPythonOperator:
- Sends an alert email if the temperature is >= 24 degrees
- Sends an informational email otherwise
PostgresOperator:
- Creates a table
- Inserts the data into the table

  Pre-requisites

- Create a connection for file_sensor_task
- Set a variable with the file path
  . Setup and Usage
  Prerequisites
- Docker Desktop
- Python 3.7+
- Apache Airflow
- PostgreSQL

